{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks_cwt\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ILS():\n",
    "    \n",
    "    def __init__(self, n_clusters = None, min_cluster_size = None, metric = 'euclidean'):\n",
    "        \n",
    "        self.n_clusters = n_clusters # need to calculate defaults based on data set input\n",
    "        self.min_cluster_size = min_cluster_size\n",
    "        self.metric = metric\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \n",
    "        if self.min_cluster_size is None: # added just so that it will run, but need to decide on better default\n",
    "            self.min_cluster_size = int (0.05 * X.shape[0])\n",
    "        \n",
    "        self.data_set = np.concatenate((X.to_numpy(), np.zeros((X.shape[0],))))\n",
    "        self.rmin = []\n",
    "        \n",
    "        X = np.array(X)\n",
    "        unlabelled = [i + 1 for i in range(X.shape[0] - 1)] # step 1\n",
    "        label_spreading = self.label_spreading([0], unlabelled_points)\n",
    "        \n",
    "        new_centers, new_unlabelled = find_initial_points() # step 2\n",
    "        \n",
    "        label_spreading = self.label_spreading(new_centers, new_unlabelled) #step 3\n",
    "    \n",
    "    def find_minima(self):\n",
    "        '''\n",
    "        Written by Amanda Parker\n",
    "        Given the index of the peaks used for partitioning the dataset into cluster find the point of maximum density\n",
    "        OUTPUT:\n",
    "            index = list index of r_min plot \n",
    "        '''\n",
    "        \n",
    "        if self.rmin is []:\n",
    "            raise Exception(\"ILS has not been run yet\")\n",
    "        \n",
    "        filtered = guassian_filter1d(self.rmin, self.min_cluster_size) #smooth rmin\n",
    "        index = np.arange(len(filtered))\n",
    "\n",
    "        maxima = find_peaks_cwt(filtered, len(filtered) * [self.min_cluster_size])\n",
    "        maxima = [i for i in maxima if i < len(filtered) - self.min_cluster_size]\n",
    "        maxima = [i for i in maxima if i >  window] #removing peaks at the beginning and end\n",
    "        \n",
    "        betweenMax = np.split(filtered, maxima)\n",
    "        betweenIndex = np.split(index, maxima)\n",
    "\n",
    "        minVal = [min(i) for i in betweenMax]\n",
    "        subMinIndex = [np.argmin(i) for i in betweenMax]\n",
    "        minima = [betweenIndex[i][subMinIndex[i]] for i in range(len(subMinIndex))]\n",
    "        minima = [i for i in minima if i != 0]\n",
    "        \n",
    "        self.n_clusters = len(minima)\n",
    "        \n",
    "        return minima\n",
    "    \n",
    "    def find_initial_points(self):\n",
    "        \n",
    "        labelled_points = self.find_minima()\n",
    "        \n",
    "        counter = 1\n",
    "        \n",
    "        for i in labelled_points: # assign labels as integers each with different label\n",
    "            self.data_set[i, -1] = counter\n",
    "            counter += 1\n",
    "        \n",
    "        unlabelled_points = [i for i in range(len(labelled_points)) if not i in labelled_points]\n",
    "                 \n",
    "        return labelled_points, unlabelled_points\n",
    "    \n",
    "    def label_spreading(self, labelled_points, unlabelled_points):\n",
    "        '''\n",
    "        Written by Amanda Parker\n",
    "        Applies iterative label spreading to the given points\n",
    "        INPUTS:\n",
    "            labelled_points = initial points that are already labelled\n",
    "                2D array with last column the points label\n",
    "            unlabelled_points = points in the data set that are not labelled\n",
    "                2D array with last column the points label (0)\n",
    "        OUTPUTS:\n",
    "            r_min = an 1D array which contains the R_min distance for eeach iteration\n",
    "        '''\n",
    "        featureColumns = self.data_set[0, :self.data_set.shape[1]] # Keep original index columns in DF\n",
    "        indices = np.arange(self.data_set.shape[0]) \n",
    "        oldIndex = np.arange(self.data_set.shape[0]) \n",
    "       \n",
    "        labelled = self.data_set[labelled_points]\n",
    "        unlabelled = self.data_set[unlabelled_points]\n",
    "        labelColumn = self.data_set.shape[1]-1\n",
    "        # lists for ordered output data\n",
    "        outD = []\n",
    "        outID = []\n",
    "        closeID = []\n",
    "    \n",
    "        # Continue to label data points until all data points are labelled\n",
    "        while len(unlabelled) > 0 :\n",
    "            # Calculate labelled to unlabelled distances matrix (D) \n",
    "            D = pairwise_distances(\n",
    "                labelled,\n",
    "                inlabelled)\n",
    "            # Find the minimum distance between a labelled and unlabelled point\n",
    "            # first the argument in the D matrix\n",
    "            (posL, posUnL) = np.unravel_index(D.argmin(), D.shape)\n",
    "            \n",
    "            # Switch label from 0 to new label\n",
    "            unlabelled[posUnL, labelColumn] = labelled[posL,labelColumn] \n",
    "            # move newly labelled point to labelled dataframe\n",
    "            labelled = np.concatenate((labelled, unlabelled[posUnL]), axis=None)\n",
    "            # drop from unlabelled data frame\n",
    "            unlabelled = np.delete(unlabelled, idUnL, 0)\n",
    "            \n",
    "            # output the distance and id of the newly labelled point\n",
    "            outD.append(D.min())\n",
    "            outID.append(posUnL)\n",
    "            closeID.append(posL)\n",
    "            \n",
    "        # Throw error if loose or duplicate points\n",
    "        if len(labelled) + len(unlabelled) != self.data_set.shape[0] : \n",
    "            raise Exception(\n",
    "                '''The number of labelled ({}) and unlabelled ({}) points does not sum to the total ({})'''.format( len(labelled), len(unlabelled),self.data_set.shape[0]) )\n",
    "        # Reodered index for consistancy\n",
    "        newIndex = oldIndex[outID]\n",
    "        # Column 1 = indices of point in orginal dataset, Column 2 = corresponding Rmin\n",
    "        orderLabelled = np.concatenate((newIndex, outD), axis=1) \n",
    "\n",
    "        # ID of point label was spread from\n",
    "        closest = np.concatenate((newIndex, closeID), axis=1)\n",
    "\n",
    "        newLabels = labelled[:,self.data_set.shape[1]-1]\n",
    "        # return\n",
    "        return newLabels, np.concatenate((orderLabelled, closest), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
